#!/bin/sh

# To submit this file, use: `qsub switch_many_nodes.qsub`

# Job label
#PBS -N Switch_2158
# Please keep nodes below 8. Each node has 8 processors & 24GB RAM
#PBS -l nodes=1:ppn=1
# How long you expect the job to run. The PBS scheduler will kill the job after this long. 72h is the maximum. Format is HH:MM:SS
#PBS -l walltime=72:00:00
# Name of the files to direct stdout and stderr. These files will be written to the working directory. 
#PBS -o logs/outfile
#PBS -e logs/errfile
# The scheduler will send updates to this email.
##PBS -M jameshenrynelson@gmail.com
# When do you want notifications? a = abort (aka failure), b = begin, e = end (without crashing)
#PBS -m bae
# Name of queue to use for this job. `qstat -q` lists the available queues (4 for now). `qstat` without options shows the jobs each queue.
#PBS -q long
#
# Export all my environment variables to the job. Remove this if you don't want to export them. 
#PBS -V
#
#
## If you don't use a cd here, it will go to your home directory.
cd ~/shared/runs/2010_12_10/AMPL_2158
# Make sure the logs directory exists
if [ ! -d logs ]; then 
	mkdir logs
fi
# We'll need ampl & cplex. 
module load ampl-cplex

echo "Nodes are:"
cat $PBS_NODEFILE
echo "mpirun is starting on "$(hostname)

# This is basically the number of nodes times the ppn value given above.
NUM_PROCS=`wc -l $PBS_NODEFILE| awk '{print $1}'`
mpirun -v -np $NUM_PROCS ./run_switch.sh $NUM_PROCS
#mpirun -v -np $NUM_PROCS ./exec_and_monitor.sh $NUM_PROCS
#mpirun -v -np $NUM_PROCS ./execute_jobs.pl jobs_list
#mpirun -v -np $NUM_PROCS ./my_script.pl jobs_list
